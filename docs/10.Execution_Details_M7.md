# 1. ** M7 落地指南（草稿）**

**里程碑目标**：构建 MVP 阶段的“数据所有权”地基。这包括：

1.  **（任务 1）** 确认 MVP 核心事件。
2.  **（任务 2）** 在 `schema.prisma` 中添加 `AnalyticsEvent` 表。
3.  **（任务 3）** 创建 `trackEvent` 异步服务。
4.  **（DoD）** 单元测试 `trackEvent` 服务。

---

## 任务 1：(项目 Owner) 确认 MVP 核心事件

- **目标**：明确 M7 - M11 需要埋点的“事件名称”。
- **执行者**：项目 Owner 。
- **确认列表 **：
  - `USER_SIGNED_UP` (M8 - M11 的 `getOrCreateQuota` 触发)
  - `ASSET_UPLOADED` (M8 `upload...Action` 触发)
  - `TASK_CREATED` (M9-M10 `createServiceAction` 等触发)
  - `TASK_COMPLETED` (M8-M10 Worker 成功时触发)
  - `TASK_FAILED` (M8-M10 Worker 失败时触发)
  - `WAITLIST_JOINED` (M10 支付意愿收集触发)

---

## 任务 2：(AI IDE) `AnalyticsEvent` 表 - 已完成

- **目标**：将 M7 规划 中的 `AnalyticsEvent` 表添加到 `schema.prisma`。
- **文件**：`prisma/schema.prisma`
- **动作 (AI IDE)**：在 `schema.prisma` 文件末尾，**添加**以下新模型：

<!-- end list -->

```prisma
// AI IDE: Add this new model to prisma/schema.prisma

// NEW: For M7 MVP Business Analytics (Issue 4)
// Tracks key user actions for internal analysis (100% data ownership)
model AnalyticsEvent {
  id        String     @id @default(cuid())

  // 可以为 null (例如 M11 的 Landing Page 访问)
  userId    String?    @map("user_id")
  user      users_sync? @relation(fields: [userId], references: [id], onDelete: SetNull, onUpdate: Cascade, map: "analytics_event_user_id_fkey")

  eventName String     @map("event_name") // e.g., "TASK_CREATED"
  payload   Json?      // e.g., { "task": "match", "isFree": true }

  createdAt DateTime   @default(now()) @map("created_at")

  @@index([eventName, createdAt(sort: Desc)])
  @@index([userId, createdAt(sort: Desc)])
  @@map("analytics_events")
  @@schema("public")
}
```

---

## 任务 3：(项目 Owner) 执行数据库迁移 - 已完成

- **目标**：将 `AnalyticsEvent` 表应用到数据库。
- **执行者**：项目 Owner（你）
- **动作**：
  1.  （AI IDE 完成任务 2 后）你在本地 `pull` 最新代码。
  2.  在你的项目根目录运行：
      ```bash
      pnpm dlx prisma migrate dev --name add-analytics-event-table
      ```
  3.  （可选）使用 `prisma studio` 检查新表是否已创建。
  4.  **将 `prisma/migrations` 文件夹 push 到 GitHub**。

---

## 任务 4：(AI IDE) `trackEvent` 服务

- **目标**：创建 `lib/analytics.ts` 模块，提供一个**异步、非阻塞 ("fire-and-forget")** 的事件跟踪函数。
- **规范**：
  - 遵循 Rule 4 (DAL)：不直接 `import { db }`，而是通过 DAL 封装（尽管这里 DAL 很薄）。trackEvent 内部必须 catch 自己的错误，只在 console.error 打印，绝不能向 Server Action 抛出异常（Rule 7.6 容错性）。
  - 遵循 M7 规划：必须是异步的，**绝不** `await` 数据库写入，以免阻塞 Server Action 的主响应。
- **文件**：`lib/analytics/index.ts` (或 `lib/analytics.ts`)

<!-- end list -->

```typescript
// AI IDE: Create this file at lib/analytics/index.ts
import { db } from '@/lib/prisma' //
import { Prisma } from '@prisma/client'

/**
 * M7 核心：跟踪一个业务分析事件
 * 这是一个 "fire-and-forget" 函数，它不会被 await
 * * @param userId (Nullable) 关联的用户 ID
 * @param eventName 事件名称 (e.g., "TASK_CREATED")
 * @param payload 附带的 JSON 数据 (e.g., { "isFree": true })
 */
export function trackEvent(
  userId: string | null | undefined,
  eventName: string,
  payload?: Prisma.JsonValue
) {
  // 规范：异步非阻塞
  // 我们有意不 await 这个 promise，以便 Server Action 可以立即返回。
  // Vercel Serverless 会在后台处理这个 promise。
  db.analyticsEvent
    .create({
      data: {
        userId: userId || null,
        eventName: eventName,
        payload: payload || Prisma.JsonNull,
      },
    })
    .catch((error) => {
      // 即使日志记录失败，也不应使主应用程序崩溃。
      // 我们只在服务器控制台中记录这个内部错误。
      console.error(
        `[AnalyticsError] Failed to track event '${eventName}':`,
        error
      )
    })
}
```

---

## 任务 5：(AI IDE) 单元测试 `trackEvent` (M7 DoD)

- **目标**：验证 `trackEvent` 函数是否以正确的参数调用了数据库。
- **规范**：遵循 Project Rule 10 (Testing)，使用 `vitest` 和 `vi.mock`。
- **文件**：`tests/analytics/analytics.test.ts`

<!-- end list -->

```typescript
// AI IDE: Create this file at tests/analytics/analytics.test.ts
import { describe, it, expect, vi, beforeEach } from 'vitest'
import { db } from '@/lib/prisma'
import { trackEvent } from '@/lib/analytics' // 导入我们要测试的函数

// 模拟 Prisma Client
vi.mock('@/lib/prisma', () => ({
  db: {
    analyticsEvent: {
      create: vi.fn().mockResolvedValue({ id: 'mock-event-id' }),
    },
  },
}))

// 将 db.analyticsEvent.create 转换为 mock
const mockCreateEvent = vi.mocked(db.analyticsEvent.create)

describe('M7 Analytics Service', () => {
  beforeEach(() => {
    // 每次测试前重置 mock
    vi.clearAllMocks()
  })

  it('should track an event with a user ID and payload', async () => {
    const userId = 'user_123'
    const eventName = 'TASK_CREATED'
    const payload = { task: 'match', isFree: true }

    trackEvent(userId, eventName, payload)

    // (M7 DoD) 验证: 检查 db.create 是否被正确调用
    // 我们使用 `expect.any(Promise)` 来验证“fire-and-forget”
    // 但在这里，为了测试简单，我们直接检查 mock 是否被调用

    // 稍作等待，以确保异步的 "fire-and-forget" 调用有时间启动
    await new Promise((resolve) => setTimeout(resolve, 0))

    expect(mockCreateEvent).toHaveBeenCalledTimes(1)
    expect(mockCreateEvent).toHaveBeenCalledWith({
      data: {
        userId: userId,
        eventName: eventName,
        payload: payload,
      },
    })
  })

  it('should track an anonymous event (null user)', async () => {
    const eventName = 'PAGE_VIEW_LANDING'

    trackEvent(null, eventName)

    await new Promise((resolve) => setTimeout(resolve, 0))

    expect(mockCreateEvent).toHaveBeenCalledTimes(1)
    expect(mockCreateEvent).toHaveBeenCalledWith({
      data: {
        userId: null,
        eventName: eventName,
        payload: expect.anything(), // Prisma.JsonNull
      },
    })
  })

  it('should not throw an error if db.create fails (fire-and-forget)', async () => {
    // 模拟数据库失败
    const dbError = new Error('Database connection failed')
    mockCreateEvent.mockRejectedValue(dbError)

    // 模拟 console.error 以捕获日志
    const consoleErrorSpy = vi
      .spyOn(console, 'error')
      .mockImplementation(() => {})

    // trackEvent 本身不应该抛错并使 Server Action 崩溃
    expect(() => {
      trackEvent('user_123', 'TASK_FAILED')
    }).not.toThrow()

    await new Promise((resolve) => setTimeout(resolve, 0))

    // 应该在后台捕获并记录了错误
    expect(consoleErrorSpy).toHaveBeenCalledWith(
      "[AnalyticsError] Failed to track event 'TASK_FAILED':",
      dbError
    )

    consoleErrorSpy.mockRestore()
  })
})
```

# 2. ** 方案评审 **

## **工作目标**

- 在不打断现有 M6 流程的前提下，为 M7 建立“异步、轻量、统一”的业务分析埋点能力，覆盖核心任务与关键异常分支，保证数据所有权与后续可扩展。
- 明确审计（audit）与业务分析（analytics）的职责边界，并给出可落地的融合策略，让现有队列与 Worker 的链路能稳定、低成本地产生可用指标。

## **总体方案**

- 建立 Analytics 统一入口：在服务端创建 `trackEvent(userId, eventName, payload?)`，采用 DAL 写库、fire-and-forget（不 await），只负责结构化落库。
- 在 Producer 和 Worker 的关键位置进行“精准、低频”的事件上报；对高频事件（如 `token`）不做 analytics 上报，避免噪音与成本。
- 审计与 analytics 分层治理：短期保持审计队列用于“操作轨迹”与“调试”，但将关键审计事件在调用点同步以 analytics 事件落库；中长期在审计队列中加入“可选持久化后端”（可直接写入 AnalyticsEvent 或单独 audit 表），形成统一数据平面。

## **事件清单（补齐及分层）**

- 业务核心（面向产品指标，M7 必做）：
  - `USER_SIGNED_UP`（已有规划）
  - `TASK_CREATED`（Producer 成功入队）
  - `TASK_COMPLETED`（Worker 成功完成）
  - `TASK_FAILED`（Worker 失败）
  - `ASSET_UPLOADED`（后续 M8 上传动作）
  - `WAITLIST_JOINED`（后续 M10 支付意愿）
- 队列与守卫（面向稳定性与容量，建议纳入 M7）：
  - `TASK_RATE_LIMITED`（Producer 侧限流命中，携带 `retryAfter`）
  - `TASK_REPLAYED`（幂等命中，携带 `idemKey`）
  - `TASK_GUARDS_BLOCKED`（并发锁或背压命中，携带 `reason` 与可选 `retryAfter`）
  - `TASK_PROVIDER_MISSING`（模型 Provider 未配置，防重复重试）
- 路由与分支（面向画像与成本，建议纳入 M7）：
  - `TASK_ROUTED`（最终模型与是否免费队列：`{ modelId, provider, isFreeQueue }`）
  - `VISION_BRANCH_USED`（变量命中 `image/jobImage`：`{ templateId }`）
- RAG（面向召回质量，建议纳入 M7（轻量））：
  - `RAG_QUERY`（可在检索服务处埋点：`{ topK, matchedCount }`）
  - 说明：RAG 的埋点量控制在“每次任务一次”，避免对检索内部多次调用重复记录。
- SSE（建议暂不入库或做低频采样）：
  - `SSE_CONNECTED` / `SSE_TERMINATED`（可采样 1%-5%，主要用于排查）

## **落地点位与协同（对应代码路径）**

- Producer 入队（`lib/queue/producer.ts`）
  - 在限流分支：记录 `TASK_RATE_LIMITED`，payload 包含 `{ templateId, kind, retryAfter }`。
  - 在幂等分支：记录 `TASK_REPLAYED`，payload 包含 `{ templateId, kind, idemKey }`。
  - 在成功发布后：记录 `TASK_CREATED`，payload 包含 `{ kind, serviceId, templateId, url, messageId, idemKey }`。
- Worker 批处理（`app/api/worker/batch/[service]/route.ts`）
  - 守卫失败：记录 `TASK_GUARDS_BLOCKED`，payload `{ reason, retryAfter? }`。
  - 视觉分支命中：在决策后记录 `VISION_BRANCH_USED`，payload `{ templateId }`。
  - 模型路由完成：记录 `TASK_ROUTED`，payload `{ provider, modelId, isFreeQueue: !userHasQuota }`。
  - 成功：记录 `TASK_COMPLETED`，payload `{ templateId, provider, modelId, inputTokens, outputTokens, latencyMs, isStream: false }`。
  - 失败：记录 `TASK_FAILED`，payload `{ templateId, code, error }`。
- Worker 流式（`app/api/worker/stream/[service]/route.ts`）
  - 守卫失败：同上。
  - Provider 未配置：记录 `TASK_PROVIDER_MISSING`（并返回 200 防止重复重试）。
  - 路由完成：记录 `TASK_ROUTED`。
  - 成功：记录 `TASK_COMPLETED`，payload `{ templateId, provider, modelId, inputTokens, outputTokens, latencyMs, isStream: true }`。
  - 失败：记录 `TASK_FAILED`，payload `{ templateId, code, error }`。
- RAG（`lib/rag/retriever.ts` 或集中到调用服务处）
  - 检索结束后：记录 `RAG_QUERY`，payload `{ topK, matchedCount }`（注意仅在“每个任务一次”的粒度，避免重复）。
- SSE 桥接（`app/api/sse-stream/route.ts`）
  - 建议暂不埋点或做低频采样，避免高并发下写库压力；若需要，采样记录 `SSE_TERMINATED`，payload `{ reason, fromLatest }`。

## **审计与 Analytics 的融合建议**

- 职责划分：
  - Analytics（业务指标）关注“任务生命周期与产品行为汇总”，用于报表与决策。
  - Audit（操作轨迹）关注“谁在何时做了什么”，用于事后追踪与风控。
- 融合策略（推荐渐进式）：
  - 短期（M7）：在关键调用点“直接”调用 `trackEvent(...)` 以写入 AnalyticsEvent；同时保留 `auditUserAction(...)` 用于轨迹与调试。避免在审计队列内做桥接（当前队列未落库，桥接会丢数据）。
  - 中期（M8/M9）：为审计队列增加可选持久化（落到独立 audit 表或统一落到 AnalyticsEvent），并在审计模块内维护一个“白名单”映射，将关键审计动作（如 `event_publish` 的 `start/done/error`）同步转写到 analytics。这样形成统一数据平面，同时保留审计的高吞吐优势。
  - 注意事项：避免双写冲突与重复；对审计 → analytics 的转写要去重（如基于 `reqId/taskId/eventName` 唯一键）。

## **实现方式与约束（遵循项目标准）**

- DAL 强制：创建 `lib/dal/analyticsEvent.ts`，提供 `createAnalyticsEvent(userId, eventName, payload)`；禁止在路由或 Server Action 中直接实例化 `PrismaClient`。
- 统一入口：创建 `lib/analytics/index.ts`，导出 `trackEvent(...)`，内部调用 DAL，且“fire-and-forget”（不 await）。
- 类型与安全：
  - 定义 `AnalyticsEventName` 联合类型或枚举，集中管理事件名称，避免拼写错误。
  - `payload` 仅包含业务相关非敏感字段（模板、模型、token 用量、延迟、错误代码等），不含凭证与私密文本。
- 低成本策略：
  - 控制埋点密度：仅关键生命周期与失败分支；高频流式 `token` 不写 analytics。
  - 与 M6 的 TTL/修剪协同：analytics 写库不需要额外 Redis I/O；Streams 的 TTL/修剪已在终止事件分支完成。

# **3. 执行规划**

## **初步任务分解（计划对齐）**

- 设计与约束
  - 定义事件枚举与 payload 规范（含字段字典与敏感数据剔除规则）。
  - 确认 `AnalyticsEvent` 表是否已存在；若未存在，补充到 `prisma/schema.prisma` 并迁移。
- 能力与测试
  - 新增 `lib/dal/analyticsEvent.ts` 与 `lib/analytics/index.ts`，实现 fire-and-forget。
  - 单测：`tests/analytics/analytics.test.ts`（使用 `vi.mock` 验证入参与非阻塞行为）。
- 代码接入（低侵入）
  - `lib/queue/producer.ts`：接入 `TASK_CREATED/TASK_RATE_LIMITED/TASK_REPLAYED`。
  - `app/api/worker/batch/[service]/route.ts`：接入守卫失败、路由、视觉分支、成功、失败。
  - `app/api/worker/stream/[service]/route.ts`：接入守卫失败、Provider 未配、路由、成功、失败。
  - RAG 检索处：补充一次性 `RAG_QUERY`。
- 文档更新
  - `docs/10.Execution_Detailes_M7.md`：补齐事件表与落地点位、DoD 与采样建议。
  - 在 `docs/2.Solution_Spec.md` 的 2.2.6 中补充融合策略与数据安全说明。

## **DoD（验收标准）**

- 单元测试通过，`trackEvent` 在核心路径被调用（mock 验证）。
- 本地或预发环境验证：触发 `TASK_CREATED/COMPLETED/FAILED` 能看到 AnalyticsEvent 的正确落库（字段齐全、无敏感信息）。
- 性能与稳定性：埋点不阻塞主流程；高频场景未出现明显写库风暴。

## **风险与治理**

- 风险：事件命名分散、重复写库、payload 失控。
- 治理：
  - 事件枚举集中管理；在编译期约束 payload 结构。
  - 严格限制写库点位（只在 Producer/Worker 完成与失败分支）。
  - 后续为审计队列加入持久化与去重（基于任务与事件键）。

# 4. ** M7 埋点上报基础建设（实际执行记录） **

本阶段目标：以“异步、轻量、统一”为原则，建立关键业务事件的上报能力，覆盖 Producer、Worker（Stream/Batch）与 RAG 检索的核心链路，确保不阻塞主流程并控制成本与噪音。

## 设计与约束

- 统一入口：`lib/analytics/index.ts` 提供 `trackEvent(eventName, ctx)`，采用 fire-and-forget 写库，不影响主流程。
- DAL 强制：所有写库仅通过 `lib/dal/analyticsEvent.ts`，内部使用 `withPrismaGuard`（重试+连接生命周期管理）。
- 非敏感字段：`payload` 仅允许非敏感业务信息；SSE 事件暂不入库（仅限关键阶段事件）。
- 事件密度控制：只跟踪低频关键事件，避免 token 级别上报与 debug 噪音。

## 事件清单（AnalyticsEventName）

- `TASK_ENQUEUED`：成功入队（Producer）。
- `TASK_RATE_LIMITED`：被限流（Producer）。
- `TASK_REPLAYED`：幂等重放（Producer）。
- `TASK_ROUTED`：路由决策（模型、队列与流式/结构化）。
- `WORKER_GUARDS_BLOCKED`：守卫阻塞（并发锁/背压）。
- `WORKER_PROVIDER_NOT_CONFIGURED`：Provider 未配置（缺少 API Key 等）。
- `TASK_COMPLETED`：任务完成（含基本用量与时延）。
- `TASK_FAILED`：任务失败（错误码与摘要）。
- `RAG_QUERY_COMPLETED`：RAG 检索完成（仅记录匹配数量与检索参数，不含文档内容）。

## 落地点位（代码引用）

- Producer：`lib/queue/producer.ts`

  - 限流返回前：`TASK_RATE_LIMITED`
  - 幂等重放返回前：`TASK_REPLAYED`
  - 成功入队后：`TASK_ENQUEUED`

- Worker（Stream）：`app/api/worker/stream/[service]/route.ts`

  - 决策完成后：`TASK_ROUTED`
  - 守卫失败（并发/背压）：`WORKER_GUARDS_BLOCKED`
  - Provider 未配置：`WORKER_PROVIDER_NOT_CONFIGURED`
  - 生成完成：`TASK_COMPLETED`
  - 生成失败：`TASK_FAILED`

- Worker（Batch）：`app/api/worker/batch/[service]/route.ts`

  - 决策完成后：`TASK_ROUTED`
  - 守卫失败（并发/背压）：`WORKER_GUARDS_BLOCKED`
  - 结构化结果完成/失败：`TASK_COMPLETED` 或 `TASK_FAILED`

- RAG 检索：`lib/rag/retriever.ts`
  - 检索结束后（一次性）：`RAG_QUERY_COMPLETED`

## Payload 约定（非敏感）

- 统一上下文：自动合并 `serviceId`、`taskId`（如可用）。
- 业务字段示例：`templateId`、`modelId`、`provider`、`isStream`、`latencyMs`、`inputTokens`、`outputTokens`、`reason/retryAfter`、`code/error`。
- RAG：仅记录 `matchedCount`、`topK`、`minScore`、`category`、`lang`；不记录文档内容与向量信息。

## 使用方式

- 新增埋点：在业务关键分支调用 `trackEvent('<EVENT_NAME>', { userId, serviceId, taskId, payload })`。
- 调整策略：事件密度与字段审查通过代码评审；严禁引入敏感信息或高频 token 级事件。

## 验收与测试

- 单元测试：`tests/analytics/analytics.test.ts` 验证上下文合并与 DAL 调用。
- 构建验证：确保新增模块通过类型检查与构建。

## 治理与成本

- 低频关键事件原则，避免写入风暴。
- 与 M6 的 Redis TTL/修剪策略互补：SSE 保持轻量，Analytics 仅做关键阶段入库。
- 后续可按需扩展审计（audit）与 analytics 的融合与持久化策略，但保持职责边界清晰。
