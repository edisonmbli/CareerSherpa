# Save Failed Optimization: Redis Lifeboat Strategy

## 1. 背景与目标
在 LLM 任务（尤其是 Paid Tier 的复杂任务）中，计算成本极高（Token生成耗时且昂贵）。当前若最后的 DB 写入步骤 (`txMarkMatchCompleted`) 即使经过重试仍失败，系统会判定任务失败并触发退款。这导致：
1.  **用户体验受损**：用户明明看到了 Streaming 生成的内容，最后却显示“失败”。
2.  **算力浪费**：昂贵的 GPU 计算成果被丢弃。
3.  **成本问题**：虽然退款了，但 API 调用成本（OpenAI/DeepSeek）已经产生。

**目标**：在 DB 暂时不可用（Network Jitter/Connection Limit）时，利用 Redis 作为“救生艇”暂存结果，确保“只要生成了就不丢弃，只要生成了就不退款”。

## 2. 核心策略：Redis Lifeboat + Lazy Read-Repair

### 2.1 为什么要利用“被动回写” (Lazy Read-Repair)？
为了最大限度节省 Vercel/QStash 的调用额度，我们**不**采取“后台轮询”或“多次定时重试”的主动策略。
我们利用用户行为的自然特性：**用户生成内容后，必然会查看结果。**
因此，我们在用户**读取**数据时，顺手完成从 Redis 到 DB 的回写。这利用了现有的 HTTP 流量，零额外成本。

### 2.2 数据流设计

#### A. 写入阶段 (Worker)
在 `MatchStrategy.writeResults` 中，当 `txMarkMatchCompleted` 重试 3 次均失败后：
1.  **不抛出致命错误**，而是捕获异常。
2.  **写入 Redis**：
    *   Key: `rescue:match:{serviceId}`
    *   Value: `{ json: matchJson, timestamp: number }`
    *   TTL: **72小时** (给予足够的时间窗口等待 DB 恢复或用户访问)。
3.  **跳过退款**：
    *   因为数据已从“内存”安全转移到了“分布式缓存”，我们视为“交付成功”。
    *   跳过 `handleRefunds` 调用。
4.  **发布事件**：
    *   仍向前端发送 `MATCH_COMPLETED` 事件（携带 JSON）。
    *   **注意**：此时 DB 里的状态可能仍是 `MATCH_STREAMING` 或 `PENDING`，但这不影响前端展示（前端主要消费 SSE 事件）。

#### B. 读取/修复阶段 (Client/API)
当用户访问结果页面，或前端轮询状态时（调用 `getServiceResult` 或类似接口）：
1.  **查询 DB**：获取当前 Service 及 Match 记录。
2.  **检测是否缺损**：
    *   如果 DB 中 `matchSummaryJson` 为空，但任务应当已结束（或超时）。
    *   **Action**：查 Redis `rescue:match:{serviceId}`。
3.  **触发修复 (Self-Healing) & 状态劫持 (Status Hijacking)**：
    *   如果 Redis 中有数据：
        *   **状态劫持**：构造一个内存中的 `Service` 对象，强制将其 `currentStatus` 覆盖为 `MATCH_COMPLETED` (或 `SUMMARY_COMPLETED` 等)，确保前端 UI 解除 Loading 状态。
        *   **立即返回**：将劫持后的对象返回给前端。
        *   **异步执行**：使用 `NextJS waitUntil` 或 fire-and-forget 自我修复 DB 状态 (`txMarkMatchCompleted`)。
        *   回写成功后，删除 Redis Key。

## 3. 详细逻辑设计

### 3.1 Paid Tier 金币逻辑
*   **原则**：服务可用即收费。
*   **实现**：
    *   既然 Redis 写入成功，且我们有可靠的 Read-Repair 机制保证最终一致性，用户实际上是可以获得服务的。
    *   因此，Worker 中**不再执行 `recordRefund`**。
    *   用户看到的 UI 状态是“成功”（由 SSE 驱动），扣费也是“成功”。

### 3.2 极端情况兜底
如果用户生成后**72小时内从未查看**结果，且 DB 一直未恢复，数据将从 Redis 过期丢失。
*   **结论**：这是可接受的成本。如果用户三天都不看一眼花钱生成的报告，说明该任务价值极低。且此时金币已扣除，若用户投诉，可通过人工客服查询 Log 补偿，无需为这 <1% 的边缘 Case 引入复杂的持久化队列。

### 3.3 Downstream Service Coverage
后续服务（如 `resume_customize`, `interview_prep`）依赖 `job_match` 的输出作为 Context。
*   **入口**: `lib/dal/services.ts` -> `getServiceSummariesReadOnly`.
*   **机制**: 我们将在此函数内集成 Read-Repair 逻辑。
*   **效果**: 当后续任务启动并调用此函数读取 `matchSummaryJson` 时，如果 DB 为空，会自动从 Redis 捞回数据并修复 DB，确保后续任务能拿到完整的 Context，不会因为 DB 暂时故障而被阻塞。

## 4. Implementation Plan

### Phase 1: Shared Utilities (Redis)
*   [ ] 在 `lib/redis/keys.ts` 中定义 `RESCUE_MATCH_KEY` 生成函数。
*   [ ] 封装 `saveToRescueCache(serviceId, data)` 和 `getFromRescueCache(serviceId)`。

### Phase 2: Worker Strategy Update
*   **File**: `lib/worker/strategies/match.ts`
*   **Change**: 修改 `writeResults` 的 catch block。
    *   在此前添加的 `withRetry` 失败后，执行 `saveToRescueCache`。
    *   仅仅当 `saveToRescueCache` 也失败时，才 throw error 并触发 refund。 (Double Failure Case)

### Phase 3: DAL / Service Layer Update (Read-Repair)
*   **File**: `lib/dal/services.ts`
*   **Change**: 在读取 Match 结果的逻辑中注入“救生艇检查”。
    *   `getServiceWithContext` (用于前端展示)
    *   `getServiceSummariesReadOnly` (用于下游任务 Context)
    *   Logic:
        *   If DB data missing/pending -> Check Redis.
        *   If Hit -> Trigger Async Write-back -> Return Redis Data.
